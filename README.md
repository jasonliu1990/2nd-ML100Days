# 2nd-ML100Days
ML 100 days start from Apr 16, 2019<br>
more information: https://ai100-2.cupoy.com/
# Part 1 資料清理與數據前處理
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_001_HW.ipynb>Day 1: 資料介紹與評估資料</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_002_HW.ipynb>Day 2: EDA: Data Summary</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_003_HW.ipynb>Day 3:3-1如何新建一個 dataframe?3-2 如何讀取其他資料?</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_004_HW.ipynb>Day 4: EDA: 欄位的資料類型介紹及處理</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_005_HW.ipynb>Day 5: EDA資料分佈</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_006_HW.ipynb>Day 6: EDA: Outlier 及處理</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_007_HW.ipynb>Day 7: 常用的數值取代：中位數與分位數連續數值標準化</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_008_HW.ipynb>Day 8: DataFrame operationData frame merge/常用的 DataFrame 操作</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_009_HW.ipynb>Day 9: 程式實作 EDA: correlation/相關係數簡介</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_010_HW.ipynb>Day 10: EDA from Correlation</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_011_HW.ipynb>Day 11: EDA: 不同數值範圍間的特徵如何檢視/繪圖與樣式Kernel Density Estimation (KDE)</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_012_HW.ipynb>Day 12: EDA: 把連續型變數離散化</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_013_HW.ipynb>Day 13: 程式實作 把連續型變數離散化</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_014_HW.ipynb>Day 14: Subplots</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_015_HW.ipynb>Day 15: Heatmap & Grid-plot</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_016_HW.ipynb>Day 16: 模型初體驗 Logistic Regression</a></br>
# Part 2 資料科學特徵工程技術
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_017_HW.ipynb>Day 17: 特徵工程簡介</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_018_HW.ipynb>Day 18: 特徵類型</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_019_HW.ipynb>Day 19: 數值型特徵-補缺失值與標準化</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_020_HW.ipynb>Day 20: 數值型特徵 - 去除離群值</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_021_HW.ipynb>Day 21: 數值型特徵 - 去除偏態</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_022_HW.ipynb>Day 22: 類別型特徵 - 基礎處理</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_023_HW.ipynb>Day 23: 類別型特徵 - 均值編碼</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_024_HW.ipynb>Day 24: 類別型特徵 - 其他進階處理</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_025_HW.ipynb>Day 25: 時間型特徵</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_026_HW.ipynb>Day 26: 特徵組合 - 數值與數值組合</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_027_HW.ipynb>Day 27: 特徵組合 - 類別與數值組合</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_028_HW.ipynb>Day 28: 特徵選擇</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_029_HW.ipynb>Day 29: 特徵評估</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_030_HW.ipynb>Day 30: 分類型特徵優化 - 葉編碼</a></br>
# Part 3 機器學習基礎模型建立
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_031_HW.ipynb>Day 31: 機器學習概論</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_032_HW.ipynb>Day 32: 機器學習-流程與步驟</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_033_HW.ipynb>Day 33: 機器如何學習?</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_034_HW.ipynb>Day 34: 訓練/測試集切分的概念</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_035_HW.ipynb>Day 35: regression vs. classification</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_036_HW.ipynb>Day 36: 評估指標選定/evaluation metrics</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_037_HW.ipynb>Day 37: regression model 介紹 - 線性迴歸/羅吉斯回歸</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_038_HW.ipynb>Day 38: regression model 程式碼撰寫</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_039_HW.ipynb>Day 39: regression model 介紹 - LASSO 回歸/ Ridge 回歸</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_040_HW.ipynb>Day 40: regression model 程式碼撰寫</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_041_HW.ipynb>Day 41:tree based model - 決策樹 (Decision Tree) 模型介紹</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_042_HW.ipynb>Day 42:tree based model - 決策樹程式碼撰寫
</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_043_HW.ipynb>Day 43:tree based model - 隨機森林 (Random Forest) 介紹
</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_044_HW.ipynb>Day 44:tree based model - 隨機森林程式碼撰寫
</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_046_HW.ipynb>Day 46:tree based model - 梯度提升機程式碼撰寫
</a></br>
# Part 4 機器學習參數調整
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_047_HW.ipynb>Day 47:超參數調整與優化</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_048_HW.ipynb>Day 48:Kaggle競賽平台介紹scikit-learn-practice</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_049_HW.ipynb>Day 49:集成方法 : 混合泛化(Blending)</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_050_HW.ipynb>Day 50:集成方法 : 堆疊泛化(Stacking)</a></br>
# Part 5 非監督式機器學習
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_054_HW.ipynb>Day 54:clustering 1 非監督式機器學習簡介</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_055_HW.ipynb>Day 55:clustering 2 聚類算法</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_056_HW.ipynb>Day 56:K-mean 觀察 : 使用輪廓分析</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_057_HW.ipynb>Day 57:clustering 3 階層分群算法</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_058_HW.ipynb>Day 58:階層分群法 觀察 : 使用 2D 樣版資料集</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_059_HW.ipynb>Day 59:dimension reduction 1 降維方法-主成份分析</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_060_HW.ipynb>Day 60:PCA 觀察 : 使用手寫辨識資料集</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_061_HW.ipynb>Day 61:dimension reduction 2 降維方法-T-SNE</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_062_HW.ipynb>Day 62:t-sne 觀察 : 分群與流形還原</a></br>
# Part 6 深度學習理論和實作
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_063_HW.ipynb>Day 63:神經網路介紹</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_064_HW.ipynb>Day 64:深度學習體驗: 模型調整與學習曲線</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_065_HW.ipynb>Day 65:深度學習體驗: 啟動函數與正規化</a></br>
# Part 7 初探深度學習使用Keras
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_066_HW.ipynb>Day 66:Keras 安裝與介紹</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_067_HW.ipynb>Day 67:Keras Dataset</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_068_HW.ipynb>Day 68:Keras Sequential API</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_069_HW.ipynb>Day 69:Keras Module API</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_070_HW.ipynb>Day 70:Multi-layer Perception多層感知</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_071_HW.ipynb>Day 71:損失函數</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_072_HW.ipynb>Day 72:啟動函數</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_073_HW.ipynb>Day 73:梯度下降 Gradient Descent</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_074_HW.ipynb>Day 74:Gradient Descent 數學原理</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_075_HW.ipynb>Day 75:BackPropagation</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_076_HW.ipynb>Day 76:優化器optimizers</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_077_HW.ipynb>Day 77:訓練神經網路的細節與技巧 - Validation and overfit</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_078_HW.ipynb>Day 78:訓練神經網路前的注意事項</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_079_HW.ipynb>Day 79:訓練神經網路的細節與技巧 - Learning rate effect</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_080_HW.ipynb>Day 80:[練習 Day] 優化器與學習率的組合與比較</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_081_HW.ipynb>Day 81:訓練神經網路的細節與技巧 - Regularization</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_082_HW.ipynb>Day 82:訓練神經網路的細節與技巧 - Dropout</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_083_HW.ipynb>Day 83:訓練神經網路的細節與技巧 - Batch normalization</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_084_HW.ipynb>Day 84:[練習 Day] 正規化/機移除/批次標準化的 組合與比較</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_085_HW.ipynb>Day 85:訓練神經網路的細節與技巧 - 使用 callbacks 函數做 earlystop</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_086_HW.ipynb>Day 86:訓練神經網路的細節與技巧 - 使用 callbacks 函數儲存 model</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_087_HW.ipynb>Day 87:訓練神經網路的細節與技巧 - 使用 callbacks 函數做 reduce learning rate</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_088_HW.ipynb>Day 88:訓練神經網路的細節與技巧 - 撰寫自己的 callbacks 函數</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_089_HW.ipynb>Day 89:訓練神經網路的細節與技巧 - 訓練神經網路的細節與技巧 - 撰寫自己的 Loss function</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_090_HW.ipynb>Day 90:使用傳統電腦視覺與機器學習進行影像辨識</a></br>
<a href=https://github.com/jasonliu1990/2nd-ML100Days/blob/master/homework/Day_091_HW.ipynb>Day 91:[練習 Day] 使用傳統電腦視覺與機器學習進行影像辨識</a></br>






